# 2025-01-Generation-Models
Generation model course at Hallym University 

ì´ ì €ì¥ì†ŒëŠ” ì› ì €ìì˜ ê³µê°œëœ ì½”ë“œë¥¼ ê³µë¶€ ëª©ì ìœ¼ë¡œ ê°€ì ¸ì™€ í•œê¸€ë¡œ ì¬ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤. </br>
ì½”ë“œì˜ ì› ì €ì‘ìëŠ” ì•„ë˜ì— ëª…ì‹œí•˜ì˜€ìœ¼ë©°, ë³¸ ì €ì¥ì†ŒëŠ” ê°œì¸ í•™ìŠµ ë° ì°¸ê³ ìš©ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

ì¶œì²˜ 
- Model <a href="https://github.com/lucidrains/DALLE2-pytorch">DALLE 2-pytorch êµ¬ì¡°</a>
- Weight & Example code <a href="https://github.com/LAION-AI/dalle2-laion">DALLE 2-LION </a>

---

<img src="./dalle2.png" width="450px"></img>

## DALL-E 2 - Pytorch
PyTorchë¡œ êµ¬í˜„ëœ <a href="https://openai.com/dall-e-2/">DALLÂ·E 2</a>, OpenAIì˜ ìµœì‹  í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± ì‹ ê²½ë§ì…ë‹ˆë‹¤. 

<a href="https://youtu.be/RJwPN4qNi_Y?t=555">Yannic Kilcher ìš”ì•½ ì˜ìƒ</a> | <a href="https://www.youtube.com/watch?v=F1X4fHzF4mQ">AssemblyAI ì„¤ëª… ì˜ìƒ</a>

ì´ ëª¨ë¸ì˜ main noveltyëŠ” Prior ë„¤íŠ¸ì›Œí¬ë¼ëŠ” ì¤‘ê°„ ë ˆì´ì–´ë¥¼ ì¶”ê°€í•œ ì ìœ¼ë¡œ, ì´ ë„¤íŠ¸ì›Œí¬ëŠ” í…ìŠ¤íŠ¸ ì„ë² ë”©(CLIPì—ì„œ ìƒì„±ë¨)ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ì„ë² ë”©ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. PriorëŠ” Autoregressive íŠ¸ëœìŠ¤í¬ë¨¸ ë˜ëŠ” Diffusion ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ ì¤‘ í•˜ë‚˜ì¼ ìˆ˜ ìˆìœ¼ë©°, ì´ êµ¬í˜„ì—ì„œëŠ” ì„±ëŠ¥ì´ ê°€ì¥ ë›°ì–´ë‚œ diffusion prior ë„¤íŠ¸ì›Œí¬ë§Œ êµ¬í˜„í•©ë‹ˆë‹¤. 
(ì¬ë¯¸ìˆê²Œë„ ì´ diffusion priorëŠ” Causal transformer ë¥¼ ë…¸ì´ì¦ˆ ì œê±° ë„¤íŠ¸ì›Œí¬ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤ ğŸ˜‚)

## Pre-Trained Models
- LAIONì€ í˜„ì¬ Prior ëª¨ë¸ì„ í•™ìŠµ ì¤‘ì´ë©°, í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ëŠ” <a href="https://huggingface.co/zenglishuci/conditioned-prior">ğŸ¤—HuggingFace</a>ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆê³ , í›ˆë ¨ í†µê³„ëŠ” <a href="https://wandb.ai/nousr_laion/conditioned-prior/reports/LAION-DALLE2-PyTorch-Prior--VmlldzoyMDI2OTIx">ğŸWeights & Biases(WANDB)</a>ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- Decoder - <a href="https://wandb.ai/veldrovive/dalle2_train_decoder/runs/jkrtg0so?workspace=user-veldrovive">In-progress test run</a> ğŸš§
- Decoder - <a href="https://wandb.ai/veldrovive/dalle2_train_decoder/runs/3d5rytsa?workspace=">Another test run with sparse attention</a>
- DALL-E 2 ğŸš§ - <a href="https://github.com/LAION-AI/dalle2-laion">DALL-E 2 Laion repository</a>

- ì‚¬ìš©í•œ ì˜ˆì œëŠ” DALL-E 2ì—ì„œ ê³µê°œëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
<a href="https://github.com/LAION-AI/dalle2-laion">DALL-E 2 Laion repository</a>

## DALLE2-LION
ë‹¤ìŒì€ LAIONì—ì„œ ì‚¬ì „ í•™ìŠµí•œ DALLE-2 ëª¨ë¸ì„ ìœ„í•œ ìë£Œ ë° ë„êµ¬ ëª¨ìŒì…ë‹ˆë‹¤.</br>
ê³µì‹ ì½”ë“œë² ì´ìŠ¤ëŠ”
<a href="https://github.com/lucidrains/DALLE2-pytorch">DALLE2-PyTorch</a>
ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì˜ˆì œ ì½”ë“œëŠ” notebooks ë‚´ dalle2_laion_alpha.ipynb íŒŒì¼ë¡œ ì‹¤í–‰ê°€ëŠ¥í•©ë‹ˆë‹¤. 

### Install 
ì˜ˆì œ ì½”ë“œ ì‹¤í–‰ì´ ì•ˆëœë‹¤ë©´, ë‹¤ìŒê³¼ ê°™ì´ í™˜ê²½ì„¤ì •ì„ ìˆ˜í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤. 

conda create -n dalle2

git clone https://github.com/LAION-AI/dalle2-laion.git
cd dalle2-laion
pip install -e . 

errorê°€ ë°œìƒí•œë‹¤ë©´, 
setup.py íŒŒì¼ ë‚´ 

setup(
    name = "dalle2-laion",
    version = "0.0.1",
    packages = find_packages(exclude=[]),
    include_package_data = True,
    install_requires = [
        "packaging>=21.0",
        "pydantic>=1.9.0",
        "torch>=1.10",
        "Pillow>=9.0.0",
        "numpy>=1.20.0",
        "click>=8.0.0",
        "dalle2-pytorch"
    ]
)

ìˆ˜ì •í•´ì£¼ì„¸ìš” 

## Citations

```bibtex
@misc{ramesh2022,
    title   = {Hierarchical Text-Conditional Image Generation with CLIP Latents}, 
    author  = {Aditya Ramesh et al},
    year    = {2022}
}
```

```bibtex
@misc{crowson2022,
    author  = {Katherine Crowson},
    url     = {https://twitter.com/rivershavewings}
}
```

```bibtex
@misc{rombach2021highresolution,
    title   = {High-Resolution Image Synthesis with Latent Diffusion Models}, 
    author  = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and BjÃ¶rn Ommer},
    year    = {2021},
    eprint  = {2112.10752},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}
```

```bibtex
@article{shen2019efficient,
    author  = {Zhuoran Shen and Mingyuan Zhang and Haiyu Zhao and Shuai Yi and Hongsheng Li},
    title   = {Efficient Attention: Attention with Linear Complexities},
    journal = {CoRR},
    year    = {2018},
    url     = {http://arxiv.org/abs/1812.01243},
}
```

```bibtex
@article{Yu2021VectorquantizedIM,
    title   = {Vector-quantized Image Modeling with Improved VQGAN},
    author  = {Jiahui Yu and Xin Li and Jing Yu Koh and Han Zhang and Ruoming Pang and James Qin and Alexander Ku and Yuanzhong Xu and Jason Baldridge and Yonghui Wu},
    journal = {ArXiv},
    year    = {2021},
    volume  = {abs/2110.04627}
}
```

```bibtex
@article{Shleifer2021NormFormerIT,
    title   = {NormFormer: Improved Transformer Pretraining with Extra Normalization},
    author  = {Sam Shleifer and Jason Weston and Myle Ott},
    journal = {ArXiv},
    year    = {2021},
    volume  = {abs/2110.09456}
}
```

```bibtex
@article{Yu2022CoCaCC,
    title   = {CoCa: Contrastive Captioners are Image-Text Foundation Models},
    author  = {Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
    journal = {ArXiv},
    year    = {2022},
    volume  = {abs/2205.01917}
}
```

```bibtex
@misc{wang2021crossformer,
    title   = {CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention},
    author  = {Wenxiao Wang and Lu Yao and Long Chen and Binbin Lin and Deng Cai and Xiaofei He and Wei Liu},
    year    = {2021},
    eprint  = {2108.00154},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}
```

```bibtex
@article{ho2021cascaded,
    title   = {Cascaded Diffusion Models for High Fidelity Image Generation},
    author  = {Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J and Norouzi, Mohammad and Salimans, Tim},
    journal = {arXiv preprint arXiv:2106.15282},
    year    = {2021}
}
```

```bibtex
@misc{Saharia2022,
    title   = {Imagen: unprecedented photorealism Ã— deep level of language understanding},
    author  = {Chitwan Saharia*, William Chan*, Saurabh Saxenaâ€ , Lala Liâ€ , Jay Whangâ€ , Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Hoâ€ , David Fleetâ€ , Mohammad Norouzi*},
    year    = {2022}
}
```

```bibtex
@article{Choi2022PerceptionPT,
    title   = {Perception Prioritized Training of Diffusion Models},
    author  = {Jooyoung Choi and Jungbeom Lee and Chaehun Shin and Sungwon Kim and Hyunwoo J. Kim and Sung-Hoon Yoon},
    journal = {ArXiv},
    year    = {2022},
    volume  = {abs/2204.00227}
}
```

```bibtex
@article{Saharia2021PaletteID,
    title   = {Palette: Image-to-Image Diffusion Models},
    author  = {Chitwan Saharia and William Chan and Huiwen Chang and Chris A. Lee and Jonathan Ho and Tim Salimans and David J. Fleet and Mohammad Norouzi},
    journal = {ArXiv},
    year    = {2021},
    volume  = {abs/2111.05826}
}
```

```bibtex
@article{Lugmayr2022RePaintIU,
    title   = {RePaint: Inpainting using Denoising Diffusion Probabilistic Models},
    author  = {Andreas Lugmayr and Martin Danelljan and Andr{\'e}s Romero and Fisher Yu and Radu Timofte and Luc Van Gool},
    journal = {ArXiv},
    year    = {2022},
    volume  = {abs/2201.09865}
}
```

```bibtex
@misc{chen2022analog,
    title   = {Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning},
    author  = {Ting Chen and Ruixiang Zhang and Geoffrey Hinton},
    year    = {2022},
    eprint  = {2208.04202},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}
```

```bibtex
@article{Qiao2019WeightS,
    title   = {Weight Standardization},
    author  = {Siyuan Qiao and Huiyu Wang and Chenxi Liu and Wei Shen and Alan Loddon Yuille},
    journal = {ArXiv},
    year    = {2019},
    volume  = {abs/1903.10520}
}
```

```bibtex
@inproceedings{rogozhnikov2022einops,
    title   = {Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation},
    author  = {Alex Rogozhnikov},
    booktitle = {International Conference on Learning Representations},
    year    = {2022},
    url     = {https://openreview.net/forum?id=oapKSVM2bcj}
}
```

```bibtex
@article{Sunkara2022NoMS,
    title   = {No More Strided Convolutions or Pooling: A New CNN Building Block for Low-Resolution Images and Small Objects},
    author  = {Raja Sunkara and Tie Luo},
    journal = {ArXiv},
    year    = {2022},
    volume  = {abs/2208.03641}
}
```

```bibtex
@article{Salimans2022ProgressiveDF,
    title   = {Progressive Distillation for Fast Sampling of Diffusion Models},
    author  = {Tim Salimans and Jonathan Ho},
    journal = {ArXiv},
    year    = {2022},
    volume  = {abs/2202.00512}
}
```

*Creating noise from data is easy; creating data from noise is generative modeling.* - <a href="https://arxiv.org/abs/2011.13456">Yang Song's paper</a>
